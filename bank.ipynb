{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github: https://github.com/Sammat2507/proyecto-sprint-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, precision_recall_curve, f1_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "bank = pd.read_csv('Churn.csv')\n",
    "bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RowNumber  CustomerId  CreditScore  Age  Tenure  Balance  NumOfProducts  \\\n",
      "0             1    15634602          619   42       2        0              1   \n",
      "1             2    15647311          608   41       1    83807              1   \n",
      "2             3    15619304          502   42       8   159660              3   \n",
      "3             4    15701354          699   39       1        0              2   \n",
      "4             5    15737888          850   43       2   125510              1   \n",
      "...         ...         ...          ...  ...     ...      ...            ...   \n",
      "9995       9996    15606229          771   39       5        0              2   \n",
      "9996       9997    15569892          516   35      10    57369              1   \n",
      "9997       9998    15584532          709   36       7        0              1   \n",
      "9998       9999    15682355          772   42       3    75075              2   \n",
      "9999      10000    15628319          792   28       0   130142              1   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
      "0             1               1           101348       1                  0   \n",
      "1             0               1           112542       0                  0   \n",
      "2             1               0           113931       1                  0   \n",
      "3             0               0            93826       0                  0   \n",
      "4             1               1            79084       0                  0   \n",
      "...         ...             ...              ...     ...                ...   \n",
      "9995          1               0            96270       0                  0   \n",
      "9996          1               1           101699       0                  0   \n",
      "9997          0               1            42085       1                  0   \n",
      "9998          1               0            92888       1                  1   \n",
      "9999          1               0            38190       0                  0   \n",
      "\n",
      "      Geography_Spain  Gender_Male  \n",
      "0                   0            0  \n",
      "1                   1            0  \n",
      "2                   0            0  \n",
      "3                   0            0  \n",
      "4                   1            0  \n",
      "...               ...          ...  \n",
      "9995                0            1  \n",
      "9996                0            1  \n",
      "9997                0            0  \n",
      "9998                0            1  \n",
      "9999                0            0  \n",
      "\n",
      "[10000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "bank = bank.drop('Surname', axis=1)\n",
    "bank = pd.get_dummies(bank, columns=['Geography', 'Gender'], drop_first=True)\n",
    "bank = bank.fillna(0)\n",
    "bank = bank.astype(int)\n",
    "print(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target = bank['Exited']\n",
    "features = bank.drop('Exited', axis=1)\n",
    "print(target.value_counts(normalize=True))\n",
    "train_features, test_features, train_target, test_target =  train_test_split(features, target, test_size=0.2, random_state=12345)\n",
    "train_features, valid_features, train_target, valid_target = train_test_split(train_features, train_target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tenemos un desequilibrio ya que los datos en un 80% de los casos son 0. Esto puede hacer que el modelo no aprenda a predecir los casos en los que la respuesta correcta es 1, por esto coincidero que debemos jÂ¿hacer un sobre muestreo o submuestreo para equilibrarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    0.507091\n",
      "1    0.492909\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_valid_upsampled, target_valid_upsampled = upsample(valid_features, valid_target, 4)\n",
    "features_train_upsampled, target_train_upsampled = upsample(train_features, train_target, 4)\n",
    "print(target_valid_upsampled.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_score = 0.59\n",
    "best_depth = 0\n",
    "for depth in range(1, 16, 1): \n",
    "    model_forest = RandomForestClassifier(random_state=54321, max_depth=depth, n_estimators=20) \n",
    "    model_forest.fit(features_train_upsampled, target_train_upsampled) \n",
    "    predictions_forest = model_forest.predict(features_valid_upsampled)\n",
    "    score = f1_score(target_valid_upsampled, predictions_forest) \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        print(best_depth)\n",
    "        print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7245791245791245\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(random_state=54321, max_depth=6, n_estimators=100) \n",
    "model_forest.fit(features_train_upsampled, target_train_upsampled) \n",
    "predictions_forest = model_forest.predict(features_valid_upsampled)\n",
    "score_forest = f1_score(target_valid_upsampled, predictions_forest)\n",
    "print(score_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5741176470588234\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_logistic.fit(features_train_upsampled, target_train_upsampled)\n",
    "predictions_logistic = model_logistic.predict(features_valid_upsampled)\n",
    "score_logistic = f1_score(target_valid_upsampled, predictions_logistic)\n",
    "print(score_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61875\n"
     ]
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=12345)\n",
    "model_tree.fit(features_train_upsampled, target_train_upsampled)\n",
    "predictions_tree = model_tree.predict(features_valid_upsampled)\n",
    "score_tree = f1_score(target_valid_upsampled, predictions_tree)\n",
    "print(score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6149532710280374\n"
     ]
    }
   ],
   "source": [
    "model_forest_test_predictions = model_forest.predict(test_features)\n",
    "model_forest_test_score = f1_score(test_target, model_forest_test_predictions)\n",
    "print(model_forest_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El mejor modelo de clasificacion teniendo en cuenta el f1_score es el randomforestclassifier, esto debido a que con el conjunto de validacion tiene un score de 0.72 y con el de prueba tiene 0.61 superando el objetivo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
